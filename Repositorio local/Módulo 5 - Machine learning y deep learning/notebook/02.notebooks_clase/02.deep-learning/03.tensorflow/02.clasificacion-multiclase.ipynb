{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Keras\n",
    "\n",
    "* \"y\" es números enteros (índices de clase: 0, 1, 2, 3....): SparseCategoricalCrossentropy\n",
    "* encoding de la salida OneHot: CategoricalCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577910</td>\n",
       "      <td>-1.175159</td>\n",
       "      <td>3.182231</td>\n",
       "      <td>0.404955</td>\n",
       "      <td>-0.613865</td>\n",
       "      <td>-1.039464</td>\n",
       "      <td>-0.239075</td>\n",
       "      <td>-2.836809</td>\n",
       "      <td>-8.026848</td>\n",
       "      <td>-9.041112</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.014423</td>\n",
       "      <td>-0.923978</td>\n",
       "      <td>1.094650</td>\n",
       "      <td>0.711980</td>\n",
       "      <td>1.824328</td>\n",
       "      <td>2.145572</td>\n",
       "      <td>0.051517</td>\n",
       "      <td>-3.797374</td>\n",
       "      <td>1.102314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.256100</td>\n",
       "      <td>0.919359</td>\n",
       "      <td>1.291473</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>1.660010</td>\n",
       "      <td>-0.552647</td>\n",
       "      <td>0.659944</td>\n",
       "      <td>-1.471791</td>\n",
       "      <td>0.089973</td>\n",
       "      <td>-0.870679</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.269361</td>\n",
       "      <td>0.624425</td>\n",
       "      <td>0.528576</td>\n",
       "      <td>-2.705067</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>-2.075426</td>\n",
       "      <td>-1.278485</td>\n",
       "      <td>0.824840</td>\n",
       "      <td>-0.712165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263308</td>\n",
       "      <td>-1.464582</td>\n",
       "      <td>1.580419</td>\n",
       "      <td>0.452207</td>\n",
       "      <td>0.693424</td>\n",
       "      <td>-0.664855</td>\n",
       "      <td>-2.134743</td>\n",
       "      <td>-3.664896</td>\n",
       "      <td>-3.941314</td>\n",
       "      <td>-4.077946</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652247</td>\n",
       "      <td>0.734020</td>\n",
       "      <td>-0.504239</td>\n",
       "      <td>-1.229404</td>\n",
       "      <td>1.276939</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>-1.459663</td>\n",
       "      <td>-2.030924</td>\n",
       "      <td>-2.562835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.327166</td>\n",
       "      <td>2.972473</td>\n",
       "      <td>2.546896</td>\n",
       "      <td>-0.887235</td>\n",
       "      <td>0.763177</td>\n",
       "      <td>2.039143</td>\n",
       "      <td>-1.942751</td>\n",
       "      <td>-0.079054</td>\n",
       "      <td>4.994518</td>\n",
       "      <td>-3.459207</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.096714</td>\n",
       "      <td>2.801948</td>\n",
       "      <td>-0.499836</td>\n",
       "      <td>0.922420</td>\n",
       "      <td>0.170235</td>\n",
       "      <td>2.051526</td>\n",
       "      <td>1.737861</td>\n",
       "      <td>1.805639</td>\n",
       "      <td>2.357027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.033218</td>\n",
       "      <td>-1.179213</td>\n",
       "      <td>0.779208</td>\n",
       "      <td>1.454919</td>\n",
       "      <td>2.839628</td>\n",
       "      <td>1.145734</td>\n",
       "      <td>2.988370</td>\n",
       "      <td>6.476426</td>\n",
       "      <td>8.485573</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315190</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>1.876118</td>\n",
       "      <td>-0.038665</td>\n",
       "      <td>-2.712738</td>\n",
       "      <td>0.374466</td>\n",
       "      <td>-0.720040</td>\n",
       "      <td>0.809654</td>\n",
       "      <td>-2.902803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.577910  -1.175159   3.182231   0.404955  -0.613865  -1.039464   \n",
       "1  -3.256100   0.919359   1.291473   0.030575   1.660010  -0.552647   \n",
       "2   0.263308  -1.464582   1.580419   0.452207   0.693424  -0.664855   \n",
       "3   2.327166   2.972473   2.546896  -0.887235   0.763177   2.039143   \n",
       "4   0.047870   0.033218  -1.179213   0.779208   1.454919   2.839628   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_12  feature_13  \\\n",
       "0  -0.239075  -2.836809  -8.026848   -9.041112  ...   -3.014423   -0.923978   \n",
       "1   0.659944  -1.471791   0.089973   -0.870679  ...   -3.269361    0.624425   \n",
       "2  -2.134743  -3.664896  -3.941314   -4.077946  ...   -2.652247    0.734020   \n",
       "3  -1.942751  -0.079054   4.994518   -3.459207  ...   -4.096714    2.801948   \n",
       "4   1.145734   2.988370   6.476426    8.485573  ...    1.315190    0.065581   \n",
       "\n",
       "   feature_14  feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "0    1.094650    0.711980    1.824328    2.145572    0.051517   -3.797374   \n",
       "1    0.528576   -2.705067    0.700740   -2.075426   -1.278485    0.824840   \n",
       "2   -0.504239   -1.229404    1.276939    0.018643   -1.459663   -2.030924   \n",
       "3   -0.499836    0.922420    0.170235    2.051526    1.737861    1.805639   \n",
       "4    1.876118   -0.038665   -2.712738    0.374466   -0.720040    0.809654   \n",
       "\n",
       "   feature_20  class  \n",
       "0    1.102314      0  \n",
       "1   -0.712165      1  \n",
       "2   -2.562835      0  \n",
       "3    2.357027      0  \n",
       "4   -2.902803      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=5000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=3,\n",
    "    weights=[1/3]*3, # 3 clases balanceadas\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(1, 21)])\n",
    "df['class'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicar one hot encoder a las salidas y para poder calcular métricas como precision, recall, auc\n",
    "# precision, recall, auc de keras esperan valores en el formato one-hot\n",
    "# garantiza que las métricas funcionen correctamente sin ajustes extra en las métricas\n",
    "y_train_encoded = keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_encoded = keras.utils.to_categorical(y_test, num_classes=3)\n",
    "y_train_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.5983 - auc: 0.7767 - loss: 0.8716 - precision: 0.6667 - recall: 0.4491 - val_accuracy: 0.8200 - val_auc: 0.9428 - val_loss: 0.4950 - val_precision: 0.8519 - val_recall: 0.7550\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9529 - loss: 0.4471 - precision: 0.8813 - recall: 0.8038 - val_accuracy: 0.8575 - val_auc: 0.9637 - val_loss: 0.3812 - val_precision: 0.8833 - val_recall: 0.8325\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8914 - auc: 0.9704 - loss: 0.3426 - precision: 0.9130 - recall: 0.8669 - val_accuracy: 0.8775 - val_auc: 0.9714 - val_loss: 0.3308 - val_precision: 0.8967 - val_recall: 0.8575\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9080 - auc: 0.9783 - loss: 0.2877 - precision: 0.9182 - recall: 0.8852 - val_accuracy: 0.8938 - val_auc: 0.9755 - val_loss: 0.3022 - val_precision: 0.9057 - val_recall: 0.8763\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9187 - auc: 0.9833 - loss: 0.2506 - precision: 0.9292 - recall: 0.9046 - val_accuracy: 0.9000 - val_auc: 0.9776 - val_loss: 0.2850 - val_precision: 0.9079 - val_recall: 0.8875\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9257 - auc: 0.9864 - loss: 0.2242 - precision: 0.9362 - recall: 0.9185 - val_accuracy: 0.9025 - val_auc: 0.9784 - val_loss: 0.2764 - val_precision: 0.9080 - val_recall: 0.8888\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9322 - auc: 0.9885 - loss: 0.2038 - precision: 0.9406 - recall: 0.9253 - val_accuracy: 0.9062 - val_auc: 0.9792 - val_loss: 0.2717 - val_precision: 0.9149 - val_recall: 0.9000\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9384 - auc: 0.9902 - loss: 0.1879 - precision: 0.9474 - recall: 0.9343 - val_accuracy: 0.9087 - val_auc: 0.9790 - val_loss: 0.2686 - val_precision: 0.9151 - val_recall: 0.9025\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9450 - auc: 0.9914 - loss: 0.1747 - precision: 0.9526 - recall: 0.9384 - val_accuracy: 0.9100 - val_auc: 0.9795 - val_loss: 0.2675 - val_precision: 0.9161 - val_recall: 0.9013\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9528 - auc: 0.9924 - loss: 0.1629 - precision: 0.9574 - recall: 0.9461 - val_accuracy: 0.9150 - val_auc: 0.9800 - val_loss: 0.2648 - val_precision: 0.9212 - val_recall: 0.9062\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9542 - auc: 0.9932 - loss: 0.1531 - precision: 0.9568 - recall: 0.9476 - val_accuracy: 0.9175 - val_auc: 0.9806 - val_loss: 0.2631 - val_precision: 0.9213 - val_recall: 0.9075\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9557 - auc: 0.9939 - loss: 0.1439 - precision: 0.9591 - recall: 0.9510 - val_accuracy: 0.9137 - val_auc: 0.9803 - val_loss: 0.2649 - val_precision: 0.9178 - val_recall: 0.9075\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9597 - auc: 0.9946 - loss: 0.1363 - precision: 0.9632 - recall: 0.9527 - val_accuracy: 0.9175 - val_auc: 0.9805 - val_loss: 0.2652 - val_precision: 0.9179 - val_recall: 0.9087\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9595 - auc: 0.9952 - loss: 0.1289 - precision: 0.9639 - recall: 0.9557 - val_accuracy: 0.9150 - val_auc: 0.9806 - val_loss: 0.2669 - val_precision: 0.9155 - val_recall: 0.9075\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9612 - auc: 0.9956 - loss: 0.1229 - precision: 0.9630 - recall: 0.9582 - val_accuracy: 0.9137 - val_auc: 0.9807 - val_loss: 0.2672 - val_precision: 0.9167 - val_recall: 0.9075\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9621 - auc: 0.9961 - loss: 0.1158 - precision: 0.9638 - recall: 0.9590 - val_accuracy: 0.9175 - val_auc: 0.9809 - val_loss: 0.2682 - val_precision: 0.9179 - val_recall: 0.9087\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9650 - auc: 0.9965 - loss: 0.1099 - precision: 0.9686 - recall: 0.9627 - val_accuracy: 0.9162 - val_auc: 0.9811 - val_loss: 0.2693 - val_precision: 0.9169 - val_recall: 0.9100\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9673 - auc: 0.9968 - loss: 0.1047 - precision: 0.9692 - recall: 0.9627 - val_accuracy: 0.9150 - val_auc: 0.9813 - val_loss: 0.2714 - val_precision: 0.9171 - val_recall: 0.9125\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9695 - auc: 0.9973 - loss: 0.0988 - precision: 0.9726 - recall: 0.9664 - val_accuracy: 0.9200 - val_auc: 0.9817 - val_loss: 0.2701 - val_precision: 0.9232 - val_recall: 0.9162\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - auc: 0.9976 - loss: 0.0930 - precision: 0.9764 - recall: 0.9698 - val_accuracy: 0.9187 - val_auc: 0.9816 - val_loss: 0.2727 - val_precision: 0.9210 - val_recall: 0.9175\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9753 - auc: 0.9979 - loss: 0.0876 - precision: 0.9769 - recall: 0.9731 - val_accuracy: 0.9187 - val_auc: 0.9811 - val_loss: 0.2763 - val_precision: 0.9230 - val_recall: 0.9137\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9776 - auc: 0.9981 - loss: 0.0828 - precision: 0.9793 - recall: 0.9753 - val_accuracy: 0.9175 - val_auc: 0.9811 - val_loss: 0.2790 - val_precision: 0.9229 - val_recall: 0.9125\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9786 - auc: 0.9983 - loss: 0.0784 - precision: 0.9794 - recall: 0.9762 - val_accuracy: 0.9187 - val_auc: 0.9810 - val_loss: 0.2826 - val_precision: 0.9243 - val_recall: 0.9162\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9794 - auc: 0.9985 - loss: 0.0746 - precision: 0.9799 - recall: 0.9772 - val_accuracy: 0.9162 - val_auc: 0.9810 - val_loss: 0.2860 - val_precision: 0.9194 - val_recall: 0.9125\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9816 - auc: 0.9987 - loss: 0.0703 - precision: 0.9826 - recall: 0.9797 - val_accuracy: 0.9162 - val_auc: 0.9798 - val_loss: 0.2934 - val_precision: 0.9206 - val_recall: 0.9125\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9822 - auc: 0.9990 - loss: 0.0668 - precision: 0.9842 - recall: 0.9812 - val_accuracy: 0.9175 - val_auc: 0.9800 - val_loss: 0.2942 - val_precision: 0.9208 - val_recall: 0.9150\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9833 - auc: 0.9992 - loss: 0.0619 - precision: 0.9838 - recall: 0.9816 - val_accuracy: 0.9162 - val_auc: 0.9802 - val_loss: 0.2984 - val_precision: 0.9194 - val_recall: 0.9125\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9852 - auc: 0.9993 - loss: 0.0584 - precision: 0.9853 - recall: 0.9834 - val_accuracy: 0.9150 - val_auc: 0.9801 - val_loss: 0.3020 - val_precision: 0.9194 - val_recall: 0.9125\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9875 - auc: 0.9995 - loss: 0.0542 - precision: 0.9882 - recall: 0.9856 - val_accuracy: 0.9150 - val_auc: 0.9801 - val_loss: 0.3069 - val_precision: 0.9182 - val_recall: 0.9125\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9873 - auc: 0.9996 - loss: 0.0505 - precision: 0.9883 - recall: 0.9862 - val_accuracy: 0.9187 - val_auc: 0.9801 - val_loss: 0.3112 - val_precision: 0.9209 - val_recall: 0.9162\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9887 - auc: 0.9997 - loss: 0.0473 - precision: 0.9892 - recall: 0.9882 - val_accuracy: 0.9162 - val_auc: 0.9802 - val_loss: 0.3168 - val_precision: 0.9181 - val_recall: 0.9112\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9898 - auc: 0.9997 - loss: 0.0443 - precision: 0.9902 - recall: 0.9892 - val_accuracy: 0.9200 - val_auc: 0.9805 - val_loss: 0.3184 - val_precision: 0.9221 - val_recall: 0.9175\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9919 - auc: 0.9998 - loss: 0.0406 - precision: 0.9923 - recall: 0.9912 - val_accuracy: 0.9162 - val_auc: 0.9798 - val_loss: 0.3256 - val_precision: 0.9183 - val_recall: 0.9137\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9925 - auc: 0.9999 - loss: 0.0372 - precision: 0.9931 - recall: 0.9920 - val_accuracy: 0.9162 - val_auc: 0.9803 - val_loss: 0.3248 - val_precision: 0.9196 - val_recall: 0.9150\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9947 - auc: 0.9999 - loss: 0.0340 - precision: 0.9950 - recall: 0.9940 - val_accuracy: 0.9187 - val_auc: 0.9803 - val_loss: 0.3339 - val_precision: 0.9210 - val_recall: 0.9175\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9948 - auc: 0.9999 - loss: 0.0319 - precision: 0.9948 - recall: 0.9937 - val_accuracy: 0.9187 - val_auc: 0.9793 - val_loss: 0.3397 - val_precision: 0.9208 - val_recall: 0.9150\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - auc: 0.9999 - loss: 0.0293 - precision: 0.9977 - recall: 0.9954 - val_accuracy: 0.9187 - val_auc: 0.9793 - val_loss: 0.3429 - val_precision: 0.9220 - val_recall: 0.9162\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9962 - auc: 1.0000 - loss: 0.0274 - precision: 0.9971 - recall: 0.9959 - val_accuracy: 0.9225 - val_auc: 0.9785 - val_loss: 0.3488 - val_precision: 0.9247 - val_recall: 0.9212\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 0.0251 - precision: 0.9983 - recall: 0.9983 - val_accuracy: 0.9200 - val_auc: 0.9786 - val_loss: 0.3549 - val_precision: 0.9246 - val_recall: 0.9200\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 0.0233 - precision: 0.9992 - recall: 0.9983 - val_accuracy: 0.9212 - val_auc: 0.9788 - val_loss: 0.3584 - val_precision: 0.9246 - val_recall: 0.9200\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 0.0219 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.9225 - val_auc: 0.9774 - val_loss: 0.3676 - val_precision: 0.9247 - val_recall: 0.9212\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 0.0200 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.9237 - val_auc: 0.9774 - val_loss: 0.3743 - val_precision: 0.9259 - val_recall: 0.9212\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 0.0185 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 0.9237 - val_auc: 0.9776 - val_loss: 0.3764 - val_precision: 0.9270 - val_recall: 0.9212\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 0.0168 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 0.9237 - val_auc: 0.9776 - val_loss: 0.3852 - val_precision: 0.9271 - val_recall: 0.9225\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0158 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9212 - val_auc: 0.9775 - val_loss: 0.3897 - val_precision: 0.9246 - val_recall: 0.9200\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0144 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9200 - val_auc: 0.9774 - val_loss: 0.3974 - val_precision: 0.9234 - val_recall: 0.9187\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0132 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9225 - val_auc: 0.9766 - val_loss: 0.3993 - val_precision: 0.9260 - val_recall: 0.9225\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0120 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9212 - val_auc: 0.9766 - val_loss: 0.4086 - val_precision: 0.9234 - val_recall: 0.9187\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0112 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9200 - val_auc: 0.9765 - val_loss: 0.4122 - val_precision: 0.9222 - val_recall: 0.9187\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0103 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9187 - val_auc: 0.9751 - val_loss: 0.4213 - val_precision: 0.9221 - val_recall: 0.9175\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0096 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9212 - val_auc: 0.9752 - val_loss: 0.4261 - val_precision: 0.9235 - val_recall: 0.9200\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0087 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9187 - val_auc: 0.9750 - val_loss: 0.4331 - val_precision: 0.9198 - val_recall: 0.9175\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0080 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9187 - val_auc: 0.9751 - val_loss: 0.4431 - val_precision: 0.9198 - val_recall: 0.9175\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0076 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9175 - val_auc: 0.9752 - val_loss: 0.4443 - val_precision: 0.9197 - val_recall: 0.9162\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 0.0068 - precision: 0.9995 - recall: 0.9995 - val_accuracy: 0.9187 - val_auc: 0.9736 - val_loss: 0.4550 - val_precision: 0.9210 - val_recall: 0.9175\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0065 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9175 - val_auc: 0.9745 - val_loss: 0.4544 - val_precision: 0.9186 - val_recall: 0.9175\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0060 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9175 - val_auc: 0.9742 - val_loss: 0.4648 - val_precision: 0.9210 - val_recall: 0.9175\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0057 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9162 - val_auc: 0.9744 - val_loss: 0.4726 - val_precision: 0.9173 - val_recall: 0.9150\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0052 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9162 - val_auc: 0.9742 - val_loss: 0.4785 - val_precision: 0.9184 - val_recall: 0.9150\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0049 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9137 - val_auc: 0.9742 - val_loss: 0.4856 - val_precision: 0.9160 - val_recall: 0.9137\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0046 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9137 - val_auc: 0.9742 - val_loss: 0.4902 - val_precision: 0.9172 - val_recall: 0.9137\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9125 - val_auc: 0.9742 - val_loss: 0.5022 - val_precision: 0.9136 - val_recall: 0.9125\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0042 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9733 - val_loss: 0.5101 - val_precision: 0.9111 - val_recall: 0.9100\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0040 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9100 - val_auc: 0.9741 - val_loss: 0.5130 - val_precision: 0.9111 - val_recall: 0.9100\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0037 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9100 - val_auc: 0.9724 - val_loss: 0.5222 - val_precision: 0.9122 - val_recall: 0.9087\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0039 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9062 - val_auc: 0.9731 - val_loss: 0.5207 - val_precision: 0.9074 - val_recall: 0.9062\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0039 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9087 - val_auc: 0.9725 - val_loss: 0.5253 - val_precision: 0.9110 - val_recall: 0.9087\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9894 - auc: 0.9990 - loss: 0.0374 - precision: 0.9894 - recall: 0.9894 - val_accuracy: 0.8788 - val_auc: 0.9498 - val_loss: 0.8485 - val_precision: 0.8788 - val_recall: 0.8788\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9599 - auc: 0.9908 - loss: 0.1422 - precision: 0.9603 - recall: 0.9597 - val_accuracy: 0.9038 - val_auc: 0.9621 - val_loss: 0.6109 - val_precision: 0.9048 - val_recall: 0.9025\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9916 - auc: 0.9990 - loss: 0.0337 - precision: 0.9920 - recall: 0.9916 - val_accuracy: 0.9025 - val_auc: 0.9738 - val_loss: 0.5046 - val_precision: 0.9048 - val_recall: 0.9025\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9962 - auc: 0.9999 - loss: 0.0146 - precision: 0.9962 - recall: 0.9962 - val_accuracy: 0.9025 - val_auc: 0.9694 - val_loss: 0.5384 - val_precision: 0.9025 - val_recall: 0.9025\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 0.0081 - precision: 0.9983 - recall: 0.9983 - val_accuracy: 0.9075 - val_auc: 0.9724 - val_loss: 0.5224 - val_precision: 0.9075 - val_recall: 0.9075\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0051 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9050 - val_auc: 0.9724 - val_loss: 0.5238 - val_precision: 0.9050 - val_recall: 0.9050\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0044 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9087 - val_auc: 0.9733 - val_loss: 0.5194 - val_precision: 0.9085 - val_recall: 0.9062\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0035 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9087 - val_auc: 0.9733 - val_loss: 0.5199 - val_precision: 0.9086 - val_recall: 0.9075\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0030 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9100 - val_auc: 0.9733 - val_loss: 0.5217 - val_precision: 0.9099 - val_recall: 0.9087\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0026 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9741 - val_loss: 0.5239 - val_precision: 0.9123 - val_recall: 0.9100\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0024 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9125 - val_auc: 0.9741 - val_loss: 0.5261 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0022 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9733 - val_loss: 0.5288 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9734 - val_loss: 0.5311 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9733 - val_loss: 0.5335 - val_precision: 0.9135 - val_recall: 0.9112\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0018 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9733 - val_loss: 0.5365 - val_precision: 0.9123 - val_recall: 0.9100\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9733 - val_loss: 0.5391 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9734 - val_loss: 0.5414 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9734 - val_loss: 0.5436 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0015 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9734 - val_loss: 0.5457 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9734 - val_loss: 0.5478 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9735 - val_loss: 0.5494 - val_precision: 0.9124 - val_recall: 0.9112\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9735 - val_loss: 0.5516 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9735 - val_loss: 0.5537 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9736 - val_loss: 0.5564 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9736 - val_loss: 0.5581 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9125 - val_auc: 0.9736 - val_loss: 0.5600 - val_precision: 0.9125 - val_recall: 0.9125\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0010 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5628 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 9.9956e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5651 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 9.5716e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5675 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 9.1577e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5698 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 8.7863e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5722 - val_precision: 0.9112 - val_recall: 0.9112\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 8.4227e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9737 - val_loss: 0.5755 - val_precision: 0.9111 - val_recall: 0.9100\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 8.0782e-04 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9112 - val_auc: 0.9738 - val_loss: 0.5779 - val_precision: 0.9112 - val_recall: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e49269e390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. random state\n",
    "keras.backend.clear_session()\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# 1. Arquitectura\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax') # capa de salida para clasificación multiclase, mismo número de neuronas que de clases a predecir\n",
    "])\n",
    "\n",
    "# 2. Compile\n",
    "model.compile(\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(), # si la \"y\" no está codificada a one-hot y es enteros 0, 1, 2, 3...\n",
    "    loss=keras.losses.CategoricalCrossentropy(), # si la \"y\" ya está codificada a one-hot [0, 0, 1]. En texto sería: \"categorical_crossentropy\"\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\n",
    "        'accuracy', # al escribirlo como texto Keras seleccionará el accuracy más idóneo dependiendo de si es clasificación binaria o multiclase\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall(),\n",
    "        keras.metrics.AUC()\n",
    "        ]\n",
    ")\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train_encoded, validation_split=0.2, epochs=100, verbose=1, batch_size=32) \n",
    "# model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=20, verbose=1, batch_size=32) # aprovechas mejor los datos, pero gastas la oportunidad de validar aparte, puede introducir fuga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)                │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,099</span> (66.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,099\u001b[0m (66.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,699</span> (22.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,699\u001b[0m (22.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,400</span> (44.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,400\u001b[0m (44.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(model.history.history)\n",
    "df_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(df_history):\n",
    "    train_metrics = [col for col in df_history.columns if not col.startswith('val_')]\n",
    "    for metric in train_metrics:\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.plot(df_history[metric], label=f'{metric} train')\n",
    "        \n",
    "        val_metric = f'val_{metric}'\n",
    "        if val_metric in df_history.columns:\n",
    "            plt.plot(df_history[val_metric], label=f'{metric} val test')\n",
    "            \n",
    "        plt.title(metric)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "plot_history(df_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Disminución inicial de ambas pérdidas (loss, val_loss):\n",
    "    * El modelo está aprendiendo correctamente\n",
    "    * Lo ideal es que vayan a la par\n",
    "\n",
    "Cosas que pueden ocurrir:\n",
    "\n",
    "* A partir de un epoch el loss y val_loss ya no mejoran, ya no hay más aprendizaje, no se logra mejorar más por lo que es mejor cortar ya los epochs.\n",
    "\n",
    "* El val_loss empieza a aumentar a partir de un determinado epoch. Esto sugiere overfitting el modelo está memorizando en lugar de generalizar, se aprende demasiado los datos de train, por lo que luego los datos de test no es capaz de predecirlos bien. Lo ideal es cortar en el epoch donde val_loss alcanza su mínimo.\n",
    "\n",
    "* Picos puede deberse a muchas causas:\n",
    "    * learning_rate alto podría ocasionar ajustes grandes generando inestabilidad\n",
    "    * Regularización: si no hay regularización puede haber overfitting e inestabilidad. Solución: capas Dropout\n",
    "    * Cambios en los datos de validación: validation_split se extrae de forma aleatoria en cada epoch, eso significa que en cada epoch se toman ejemplos diferentes. Si los datos son ficticios o raros eso puede dar lugar a picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - auc: 0.9767 - loss: 0.4280 - precision: 0.9262 - recall: 0.9239\n",
      "test_loss_bce 0.5063223838806152\n",
      "test_accuracy 0.9240000247955322\n",
      "test_precision 0.923923909664154\n",
      "test_recall 0.9229999780654907\n",
      "test_auc 0.9740415215492249\n"
     ]
    }
   ],
   "source": [
    "test_loss_bce, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(X_test, y_test_encoded)\n",
    "print('test_loss_bce', test_loss_bce)\n",
    "print('test_accuracy', test_accuracy)\n",
    "print('test_precision', test_precision)\n",
    "print('test_recall', test_recall)\n",
    "print('test_auc', test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.5740479e-09, 6.8927496e-14, 1.0000000e+00],\n",
       "       [9.9995565e-01, 7.8351842e-10, 4.4345135e-05],\n",
       "       [2.5641359e-04, 2.2808072e-04, 9.9951553e-01],\n",
       "       [1.0000000e+00, 4.6574625e-16, 1.2467059e-15],\n",
       "       [1.4736199e-15, 9.9999988e-01, 9.3812581e-08]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:5] # matriz de probabilidades [n_samples, n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) # devuelve la clase que tiene la probabilidad más alta: 0, 1, 2...\n",
    "y_pred_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>prediccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      real  prediccion\n",
       "480      2           2\n",
       "2575     0           0\n",
       "4452     2           2\n",
       "550      0           0\n",
       "4351     1           1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison = pd.DataFrame({'real': y_test, 'prediccion': y_pred_labels})\n",
    "df_comparison.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
