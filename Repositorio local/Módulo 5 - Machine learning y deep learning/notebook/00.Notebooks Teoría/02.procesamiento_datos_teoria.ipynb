{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30f7f00",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos\n",
    "\n",
    "**La limpieza y preparación de datos es el paso más importante en cualquier proyecto de Inteligencia Artificial y Machine Learning.**\n",
    "\n",
    "La limpieza de datos es el proceso de detectar y corregir o eliminar registros corruptos o inexactos de un conjunto de registros, tabla o base de datos y se refiere a la identificación de partes incompletas, incorrectas, inexactas o irrelevantes de los datos, para su posterior sustitución, modificación o eliminación de los datos sucios o poco precisos.\n",
    "\n",
    "El procesamiento de datos se refiere al conjunto de técnicas, métodos y procesos utilizados para transformar datos brutos en información significativa y útil. Es una parte fundamental del ciclo de vida de los datos y juega un papel crucial en el análisis de datos y la generación de conocimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eafaaa",
   "metadata": {},
   "source": [
    "### 1. Valores perdidos (NaN's)\n",
    "\n",
    "Se presentan cuando el valor para al menos un rasgo o un patrón en el conjunto de datos no se encuentra presente. Generalmente se representan con:\n",
    "\n",
    "1. **Valor fuera de rango**: -1 en un campo numérico que solo es positivo.\n",
    "\n",
    "\n",
    "2. **Caracteres especiales**: -, ? o espacio en blanco.\n",
    "\n",
    "\n",
    "3. **Valores perdidos identificados**: NaN's\n",
    "\n",
    "**Causas**: mal funcionamiento de equipos de medición, cambio en el diseño durante la captura de datos, imposibilidad de recolectar los datos, entre otras.\n",
    "\n",
    "### Estrategías de tratamiento de NaN's\n",
    "\n",
    "- _**Eliminar los patrones**_ (filas) cuyos atributos contienen valores perdidos.\n",
    "    - Pros:\n",
    "        - Simple y rápido de implementar\n",
    "    - Contras:\n",
    "        - Al eliminar una fila entera por un NaN, perdemos otros datos potencialmente valiosos que contiene esa fila.\n",
    "\n",
    "- Si el atributo que tiene valores perdidos es numérico se rellenan los valores con el _**valor promedio**_ del atributo o por la _**mediana**_.\n",
    "    - Pros:\n",
    "        - No perdemos datos.\n",
    "        - La estimación de los valores perdidos está fundamentada en la estadística descriptiva de nuestro dataset.\n",
    "    - Contras:\n",
    "        - Podemos distorsionar significativamente la distribución de los datos, sobre todo cuando tenemos muchos valores perdidos.\n",
    "\n",
    "\n",
    "- Si el atributo que tiene valores perdidos es categórico se rellenan los valores con la _**moda**_ del atributo.\n",
    "    - Pros:\n",
    "        - No perdemos datos.\n",
    "        - La estimación de los valores perdidos está fundamentada en la estadística descriptiva de nuestro dataset.\n",
    "    - Contras:\n",
    "        - Podemos distorsionar significativamente la frecuencia de las categorías en favor a la categoría mayoritaria.\n",
    "        \n",
    "- Se pueden utilizar _**métodos de imputación**_ más avanzados haciéndo uso de algoritmos como KNN (K Nearest Neighbors) para rellenar los NaNs.\n",
    "    - Pros:\n",
    "        - No perdemos datos.\n",
    "        - La estimación de los valores perdidos se hace en base a otros valores conocidos.\n",
    "        - Respetamos la distribución de los datos.\n",
    "    - Contras:\n",
    "        - Los algoritmos de imputación tienen una muy alta complejidad temporal, por lo que es mucho más costoso utilizarlos con grandes volúmenes de datos de manera directa.\n",
    "        \n",
    "- Si el atributo contiene muchos valores perdidos podemos optar por _**eliminar la columna**_ en lugar de eliminar las filas.\n",
    "    - Pros:\n",
    "        - Simple y rápido de implementar.\n",
    "    - Contras:\n",
    "        - Si el atributo resulta ser un importante predictor de la variable objetivo estaremos perdiendo datos útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c4a99",
   "metadata": {},
   "source": [
    "### 2. Valores Atípicos (Outliers)\n",
    "\n",
    "Los valores atípicos son datos que presentan una diferencia significativa del resto de elementos en un conjunto de datos o en una clase en particular.\n",
    "\n",
    "**Causas:**\n",
    "- **Malas mediciones al capturar los datos.**\n",
    "\n",
    "\n",
    "- **Mal etiquetado del patrón al asignarle una clase.**\n",
    "\n",
    "\n",
    "- **Características propias del atributo.**\n",
    "\n",
    "### Tratamiento de Outliers\n",
    "\n",
    "- Eliminar patrones atípicos que presentan _**valores evidentemente imposibles**_, un ejemplo sería edades negativas.\n",
    "    - Pros:\n",
    "        - Limpiamos los datos y mejoramos su calidad.\n",
    "    - Contras:\n",
    "        - Podemos entender también estos valores como valores perdidos, por lo que técnicas de tratado de NaNs podrían ser otra opción a considerar.\n",
    "\n",
    "- _**Normalizar los datos**_. Al aplicar una transformación que normaliza los datos, podemos ver cómo algunos eleméntos que parecían ser outliers ya no lo son.\n",
    "    - Pros:\n",
    "        - Nos da una perspectiva única sobre los datos.\n",
    "        - Podemos detectar outliers de una manera más \"justa\".\n",
    "    - Contras:\n",
    "        - Complejidad teórica. Hay que saber reconocer la distribución de datos que tenemos y qué transformación aplicarle para normalizarlos.\n",
    "\n",
    "- Utilizar la _**puntuación Z**_ para filtrar outliers. Cuando nuestros datos siguen una distribución normal, podemos establecer un umbral utilizando la puntuación Z para determinar datos normales y atípicos.\n",
    "    - Pros:\n",
    "        - Flexibilidad al modificar el parámetro Z.\n",
    "        - Muy simple y rápido de implementar.\n",
    "    - Contras:\n",
    "        - Solo es bueno con distribuciones normales.\n",
    "        - Podemos eliminar muchos datos si lo utilizamos de forma reiterada con varias columnas.\n",
    "        - Filtramos atributo por atributo, sin tener en cuenta la interacción entre variables.\n",
    "\n",
    "- Utilizar la _**valla de Tukey**_. Considerar atípicos los valores inferiores a Q1–k·RIC o superiores a Q3+k·RIC. (bigotes del boxplot). RIC = Q3 – Q1 con k=1.5.\n",
    "    - Pros:\n",
    "        - Flexibilidad al modificar el parámetro k.\n",
    "        - Robusto ante distribuciones asimétricas.\n",
    "    - Contras:\n",
    "        - Podemos eliminar muchos datos si lo utilizamos de forma reiterada con varias columnas.\n",
    "        - Filtramos atributo por atributo, sin tener en cuenta la interacción entre variables.\n",
    "        \n",
    "- _**Visualizar los datos**_. Podemos establecer un punto de corte manual para filtrar outliers partiendo de lo que vemos en una visualización de la distribución de los datos (histograma).\n",
    "    - Pros:\n",
    "        - Es múy fácil de explicar la toma de decisiones a otra persona.\n",
    "        - Más control humano y menos automatización.\n",
    "    - Contras:\n",
    "        - No siempre es fácil de ver visualmente donde se encuentran los outliers, o si existen.\n",
    "        - Filtramos atributo por atributo, sin tener en cuenta la interacción entre variables.\n",
    "\n",
    "- Aplicar métodos de _**clustering**_ que sean capaces de detectar los outliers. Ej: DBSCAN.\n",
    "    - Pros:\n",
    "        - Podemos aplicarlo con todo el dataset de golpe o solamente con las columnas que nos interesan.\n",
    "    - Contras:\n",
    "        - Es muy importante hacer un tuning correcto del modelo de clustering.\n",
    "- Aplicar métodos de _**feature selection**_ para reducir la dimensionalidad. Ej: PCA.\n",
    "    - Pros:\n",
    "        - Podemos aplicar los métodos de umbrales como la puntuación Z y valla de Tukey sin perder muchos datos.\n",
    "    - Contras:\n",
    "        - Es un proceso tedioso con ventajas marginales.\n",
    "        - Filtramos atributo por atributo, sin tener en cuenta la interacción entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d536e62c",
   "metadata": {},
   "source": [
    "### 3. Encodings\n",
    "\n",
    "Los encodings son mapas que asocian las categorías de alguna columna categórica a valores numéricos. Son necesarios para que los diferentes algoritmos puedan interpretar nuestros datos categóricos, ya que estos algoritmos solo \"entienden\" números.\n",
    "\n",
    "Scikit Learn trae varios objetos que podemos utilizar para codificar nuestras variables categóricas y convertir los valores en números:\n",
    "\n",
    "1. _**Ordinal Encoding**_: transformamos toda la columna a números enteros, si la columna tiene _**n**_ elementos únicos, va a cambiar esos elementos por lo números desde el _**0**_ hasta _**n - 1**_.\n",
    "\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Nivel Educativo</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>ESO</td>\n",
    "        </tr>\n",
    "          <td>Bachillerato</td>\n",
    "        <tr>\n",
    "          <td>Grado Universitario</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Master</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Doctorado</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Nivel Educativo Ordinal</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>4</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "\n",
    "    - Pros:\n",
    "        - Simple y rápido de implementar.\n",
    "        - Puede capturar relaciones de ordinalidad entre las categorías.\n",
    "        - Mantiene una relación equidistante entre las categorías asumiendo que siguen un orden.\n",
    "    - Contras:\n",
    "        - No es adecuado para variables categóricas nominales (sin orden), ya que puede introducir sesgos en nuestro modelo, enseñándole relaciones de ordinalidad, distancia y proporción entre categorías que no poseen dichos rasgos.\n",
    "<br>\n",
    "\n",
    "2. _**One Hot Encoding**_: este encoding se utiliza para transformar columnas categóricas en un conjunto de columnas binarias (0 o 1) que representan la presencia o ausencia de cada categoría en los datos originales.\n",
    "\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Sex</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>male</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>female</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>female</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>male</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>female</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Sex_male</th>\n",
    "          <th>Sex_female</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "    \n",
    "    - Pros:\n",
    "        - Simple y rápido de implementar.\n",
    "        - No asume orden entre las categorías.\n",
    "        - Compatible con la mayoría de los modelos de aprendizaje automático.\n",
    "    - Contras:\n",
    "        - Aumenta de manera significativa la dimensionalidad de los datos, especialmente con muchas categorías, por lo que puede generar problemas de multicolinealidad y sparsidad de datos.\n",
    "\n",
    "<br>\n",
    "\n",
    "3. _**Binary Encoding**_: Este es un método que nos permite reducir el impacto de los pesos asignados a las categorías por un encoding como el ordinal. Tenemos que representar los valores numéricos resultantes de un encoding ordinal en su forma binaria, y luego utilizar los dígitos de una manera similar a como lo hacemos en un one hot encoding.\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Nivel Educativo</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>ESO</td>\n",
    "        </tr>\n",
    "          <td>Bachillerato</td>\n",
    "        <tr>\n",
    "          <td>Grado Universitario</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Master</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Doctorado</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Nivel Educativo Ordinal</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>4</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    \n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Nivel Educativo Binary 2</th>\n",
    "          <th>Nivel Educativo Binary 1</th>\n",
    "          <th>Nivel Educativo Binary 0</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>0</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>0</td>\n",
    "          <td>1</td>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "          <td>0</td>\n",
    "          <td>0</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "\n",
    "    - Pros:\n",
    "        - Reduce la dimensionalidad en comparación con el One Hot Encoding.\n",
    "        - Reduce la ordinalidad en comparación con el Ordinal Encoding.\n",
    "    - Contras:\n",
    "        - No es capaz de solucionar por completo las desventajas de One Hot Encoding y Ordinal Encoding.\n",
    "        - Puede perder cierta información sobre la relación entre categorías y la variable objetivo.\n",
    "\n",
    "<br>\n",
    "\n",
    "4. _**Target Encoding**_: este método agrupa nuestros datos por las categorías y calcula el promedio, mediana o distribución de frecuencias de la columna _**target**_. El número obtenido para cada agrupación será el valor codificado para senda categoría.\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "          <th>Gasto</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>80</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>200</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>120</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>180</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Anciano</td>\n",
    "          <td>250</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "          <th>Gasto Promedio</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>190</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Anciano</td>\n",
    "          <td>250</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>190</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>190</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>250</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "    \n",
    "\n",
    "    - Pros:\n",
    "        - Captura la relación entre las categorías y la variable objetivo de manera directa.\n",
    "        - Conserva la dimensionalidad.\n",
    "        - Destaca en algoritmos de regresión.\n",
    "        - Se puede utilizar cuando hay muchas categorías nominales.\n",
    "    - Contras:\n",
    "        - Riesgo de sobreajuste, especialmente si las categorías tienen pocas observaciones.\n",
    "        - Puede llevar a fuga o contaminación de datos (data leakage) si no se maneja con cuidado. Es obligatorio utilizar este encoding únicamente con el conjunto de entrenamiento.\n",
    "\n",
    "<br>\n",
    "\n",
    "5. _**Leave One Out Encoding**_: Similar al target encoding, solo que el valor numérico que se asigna a cada categoría es el promedio o mediana de todo el dataset menos esa categoría.\n",
    "\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "          <th>Gasto</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>100</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>80</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>200</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>120</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>180</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Anciano</td>\n",
    "          <td>250</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "          <th>Gasto Promedio LOO</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "          <td>210.0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "          <td>137.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Anciano</td>\n",
    "          <td>136.0</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>210.0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>210.0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>137.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>210.0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>137.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>136.0</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "    \n",
    "    - Pros:\n",
    "        - Reduce el riesgo de sobreajuste asociado al Target Encoding.\n",
    "    - Contras:\n",
    "        - Es de los encodings más lentos en términos de computación.\n",
    "        - Es más complejo que otros encodings y puede ser difícil de implementar en conjunto con otras técnicas.\n",
    "\n",
    "<br>\n",
    "\n",
    "6. _**Frequency Encoding**_: También podemos asignarle a cada categoría un valor que corresponde con la frecuencia con la que aparece esa categoría en nuestro dataset.\n",
    "\n",
    "    <br>\n",
    "    <div style=\"display: flex;\">\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Joven</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Adulto</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Anciano</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Grupo de edad</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>1</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </div>\n",
    "\n",
    "    - Pros:\n",
    "        - Simple y rápida implementación\n",
    "        - Es una opción sólida cuando las frecuencias de nuestras categorías representan bien la realidad.\n",
    "        - Igual que Target Encoding y Leave One Out Encoding, se puede utilizar cuando hay muchas categorías nominales.\n",
    "    - Contras:\n",
    "        - Puede perder información sobre la relación entre las categorías y la variable objetivo.\n",
    "        - Es una muy mala opción si las frecuencias de la muestra no representan bien las frecuencias de la población."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e85672",
   "metadata": {},
   "source": [
    "### 4. Escalado de Datos\n",
    "\n",
    "El escalado de datos consiste en ajustar los valores medidos en diferentes escalas con respecto a una escala común. Esto es especialmente útil de cara a la utilización de algoritmos que comparan los atributos utilizando distancias. Si no se escalan los datos, el cálculo de distancias se verá distorsionado y se le dará mucho más peso a unos atributos que a otros, independientemente de su poder predictivo.\n",
    "\n",
    "- _**Estandarización**_: `StandardScaler()`\n",
    "\n",
    "    - Pros:\n",
    "        - Simple y fácil de implementar.\n",
    "        - Capta la media y la desviación estandar.\n",
    "    - Contras:\n",
    "        - Asume que los datos son normales.\n",
    "        - Sensible a distribuciones asimétricas y a los outliers.\n",
    "    \n",
    "    $$\n",
    "    x_{\\text{est}} = \\frac{x - \\mu}{\\sigma}\n",
    "    $$\n",
    "    \n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |         -1.78444  |        -0.383107  |          0.474263 |\n",
    "|  0   |  300 | -500 |         -0.162221 |         1.14932   |         -2.23555  |\n",
    "|  2.5 |  250 |  -12 |          0.648886 |         0.383107  |          0.414527 |\n",
    "| -1.5 |  220 |  -10 |         -0.648886 |        -0.0766214 |          0.425388 |\n",
    "|  4   |  280 |   -2 |          1.13555  |         0.842836  |          0.468832 |\n",
    "|  3   |  100 |   -5 |          0.811107 |        -1.91554   |          0.452541 |\n",
    "\n",
    "\n",
    "\n",
    "- _**Escalado Min Max**_: `MinMaxScaler()`\n",
    "\n",
    "    - Pros:\n",
    "        - Simple y fácil de implementar.\n",
    "        - Escala los datos a un rango específico (entre 0 y 1).\n",
    "        - Conserva las proporciones entre las observaciones.\n",
    "    - Contras:\n",
    "        - Muy sensible a valores atípicos, ya que afectan al rango de los datos.\n",
    "\n",
    "    $$\n",
    "    x_{\\text{min-max}} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}}\n",
    "    $$\n",
    "    \n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |          0        |              0.5  |          1        |\n",
    "|  0   |  300 | -500 |          0.555556 |              1    |          0        |\n",
    "|  2.5 |  250 |  -12 |          0.833333 |              0.75 |          0.977956 |\n",
    "| -1.5 |  220 |  -10 |          0.388889 |              0.6  |          0.981964 |\n",
    "|  4   |  280 |   -2 |          1        |              0.9  |          0.997996 |\n",
    "|  3   |  100 |   -5 |          0.888889 |              0    |          0.991984 |\n",
    "\n",
    "\n",
    "- _**Escalado Robusto**_: `RobustScaler()`\n",
    "\n",
    "    - Pros:\n",
    "        - Como su nombre indica, es robusto a los valores atípicos, ya que utiliza medianas y cuantiles.\n",
    "    - Contras:\n",
    "        - No es la mejor opción cuando la distribución de los datos es simétrica.\n",
    "        - Puede perder información en los extremos de la distribución.\n",
    "\n",
    "    $$\n",
    "    x_{\\text{robusto}} = \\frac{x - \\text{mediana}}{\\text{RIC}}\n",
    "    $$\n",
    "\n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |           -1.5625 |         -0.518519 |          0.742857 |\n",
    "|  0   |  300 | -500 |           -0.3125 |          0.962963 |        -56.2857   |\n",
    "|  2.5 |  250 |  -12 |            0.3125 |          0.222222 |         -0.514286 |\n",
    "| -1.5 |  220 |  -10 |           -0.6875 |         -0.222222 |         -0.285714 |\n",
    "|  4   |  280 |   -2 |            0.6875 |          0.666667 |          0.628571 |\n",
    "|  3   |  100 |   -5 |            0.4375 |         -2        |          0.285714 |\n",
    "\n",
    "- _**Escalado Máximo Absoluto**_: `MaxAbsScaler()`\n",
    "\n",
    "    - Pros:\n",
    "        - Igual que Min Max, pero el acota entre -1 y 1.\n",
    "    - Contras:\n",
    "        - Igual que Min Max.\n",
    "\n",
    "    $$\n",
    "    x_{\\text{abs}} = \\frac{x}{|x_{\\text{max}}|}\n",
    "    $$\n",
    "\n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |              -1   |          0.666667 |            -0.002 |\n",
    "|  0   |  300 | -500 |               0   |          1        |            -1     |\n",
    "|  2.5 |  250 |  -12 |               0.5 |          0.833333 |            -0.024 |\n",
    "| -1.5 |  220 |  -10 |              -0.3 |          0.733333 |            -0.02  |\n",
    "|  4   |  280 |   -2 |               0.8 |          0.933333 |            -0.004 |\n",
    "|  3   |  100 |   -5 |               0.6 |          0.333333 |            -0.01  |\n",
    "\n",
    "- _**Escalado Cuantil**_: `QuantileTransformer()`\n",
    "\n",
    "    - Pros:\n",
    "        - Maneja bien los valores atípicos.\n",
    "    - Contras:\n",
    "        - Puede cambiar la relación original de los datos.\n",
    "        - Requiere de un buen ajuste y es más caro computacionalmente que otros métodos.\n",
    "\n",
    "    $$\n",
    "    x_{\\text{cuantil}} = Q(x)\n",
    "    $$\n",
    "    \n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |               0   |               0.2 |               1   |\n",
    "|  0   |  300 | -500 |               0.4 |               1   |               0   |\n",
    "|  2.5 |  250 |  -12 |               0.6 |               0.6 |               0.2 |\n",
    "| -1.5 |  220 |  -10 |               0.2 |               0.4 |               0.4 |\n",
    "|  4   |  280 |   -2 |               1   |               0.8 |               0.8 |\n",
    "|  3   |  100 |   -5 |               0.8 |               0   |               0.6 |\n",
    "\n",
    "\n",
    "- _**Escalado por Potencia**_: `PowerTransformer()`\n",
    "\n",
    "    - Pros:\n",
    "        - Transforma los datos acercándolos a una distribución normal.\n",
    "        - Ayuda a reducir la varianza y los sesgos en los datos.\n",
    "    - Contras:\n",
    "        - Requiere de ajuste del parámetro λ.\n",
    "        - Más complejo y costoso que otros métodos.\n",
    "\n",
    "    $$\n",
    "    x_{\\text{potencia}} = \\begin{cases}\n",
    "  \\left(\\frac{x + \\lambda - 1}{\\lambda}\\right)^{1/2} & \\text{si} \\; \\lambda \\neq 0 \\\\\n",
    "  \\log(x + 1) & \\text{si} \\; \\lambda = 0\n",
    "\\end{cases}\n",
    "    $$\n",
    "\n",
    "\n",
    "|   x1 |   x2 |   x3 |   x1_transformada |   x2_transformada |   x3_transformada |\n",
    "|-----:|-----:|-----:|------------------:|------------------:|------------------:|\n",
    "| -5   |  200 |   -1 |         -1.56341  |         -0.577963 |          1.40598  |\n",
    "|  0   |  300 | -500 |         -0.381935 |          1.35109  |         -1.71015  |\n",
    "|  2.5 |  250 |  -12 |          0.602398 |          0.28377  |         -0.431557 |\n",
    "| -1.5 |  220 |  -10 |         -0.798842 |         -0.25775  |         -0.317165 |\n",
    "|  4   |  280 |   -2 |          1.31089  |          0.899312 |          0.885253 |\n",
    "|  3   |  100 |   -5 |          0.830905 |         -1.69846  |          0.167641 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409383b",
   "metadata": {},
   "source": [
    "### 5. Desbalance de Clases\n",
    "\n",
    "Este fenómeno se presenta cuando **el número total de instancias en una clase (clase mayoritaria) es significativamente mayor que el número de instancias de otra clase (clase minoritaria)**.\n",
    "\n",
    "Este es un problema que se presenta a menudo en situaciones comunes de la vida real. Por ejemplo imaginemos un sistema de detección de intrusos o de fraudes en tarjetas de crédito\n",
    "\n",
    "**Desventajas:**\n",
    "1. **Pobre desempeño de los modelos de predicción.**\n",
    "\n",
    "\n",
    "2. **Proceso de aprendizaje guiado por métricas globales presenta una inclinación hacia la clase mayoritaria.**\n",
    "\n",
    "\n",
    "3. **Instancias de la clase minoritaria pueden ser tratados como ruido.**\n",
    "\n",
    "\n",
    "**Soluciones:**\n",
    "1. **Undersampling**: remover algunos patrones de la clase mayoritaria.\n",
    "\n",
    "\n",
    "2. **Oversampling**: crear patrones sintéticos que se agregan a la clase minoritaria.\n",
    "\n",
    "\n",
    "3. **Híbrido**: combinar undersampling y oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288c423",
   "metadata": {},
   "source": [
    "### 6. Alta Dimensionalidad de los Atributos (Feature Selection)\n",
    "\n",
    "En ocasiones nos encontramos con conjuntos de datos con gran cantidad de atributos (columnas). No necesariamente toda la información representada por los rasgos resulta relevante para hacer predicciones. Para atacar este problema se podría recurrir a:\n",
    "\n",
    "- **Asistencia de un experto en el tema.**\n",
    "\n",
    "\n",
    "- **Métodos automáticos para la selección de características.**\n",
    " \n",
    "En general los métodos de selección de características consisten en realizar una búsqueda a través de diferentes sub-conjuntos de atributos.\n",
    "- **Métodos óptimos**: búsqueda exhaustiva, branch and bound Search.\n",
    "\n",
    "\n",
    "- **Métodos sub-óptimos**: sequential selection, stochastic search techniques (algoritmos genéticos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e986e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
