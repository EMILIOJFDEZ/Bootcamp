{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets \n",
    "\n",
    "En el contexto del aprendizaje automático con Scikit-Learn, los **datasets** son conjuntos de datos estructurados que se utilizan para entrenar y evaluar modelos. Cada dataset típicamente contiene dos componentes principales:  \n",
    "\n",
    "* **X**: Conjunto de entradas o características (features), que representan las variables independientes.  \n",
    "* **y**: Vector objetivo (target) que contiene la salida esperada o variable dependiente.\n",
    "\n",
    "\n",
    "#### Nombres:\n",
    "\n",
    "* X: Entradas / Features / Características / Atributos / Variables independientes / Variables predictoras\n",
    "\n",
    "* y: Salida / Target / Clase / Variable dependiente / Variable de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_\n",
    "\n",
    "La función `load_*` de Scikit-Learn se utiliza para cargar datasets clásicos ya incluidos en la biblioteca. Estos conjuntos de datos están documentados y se usan normalmente para aprendizaje y demostraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset Iris y verificar el tipo de objeto retornado.\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar posibles funciones de carga de datasets disponibles en sklearn\n",
    "\n",
    "datasets.load_*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción del dataset Iris\n",
    "\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de entrada (features) de Iris\n",
    "\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las características de Iris\n",
    "\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores objetivo (clases) para cada instancia\n",
    "\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las clases\n",
    "\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de pandas a partir de los datos de Iris. incluye la columna de clases\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['class'] = iris.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la forma (dimensiones) del dataframe\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch_\n",
    "\n",
    "A diferencia de `load_*`, las funciones `fetch_*` descargan datasets de fuentes externas o repositorios online (UCI, OpenML). Sirve para trabajar con datasets más grandes o personalizados que no se incluyen directamente en Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets disponibles en sklearn\n",
    "\n",
    "datasets.fetch_*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de California Housing y verificar su tipo de objeto\n",
    "\n",
    "california = datasets.fetch_california_housing()\n",
    "type(california)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de California Housing\n",
    "\n",
    "print(california.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe a partir de California Housing\n",
    "\n",
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df['price'] = california.target\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch_ con url\n",
    "\n",
    "`fetch_*` con URL permite acceder a datasets disponibles en repositorios en línea como OpenML. \n",
    "\n",
    "Por ejemplo, la URL [https://www.openml.org/search?type=data](https://www.openml.org/search?type=data) lleva a una colección de datos. Desde ahí se pueden descargar datasets por su identificador o nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset Iris desde OpenML a partir de su ID\n",
    "\n",
    "iris = datasets.fetch_openml(data_id=61)\n",
    "iris # bunch con atributos: data, feature_names, target, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset Iris desde OpenML especificando nombre, versión y parser\n",
    "\n",
    "iris = datasets.fetch_openml(name='iris', version=1, parser='auto')\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_\n",
    "\n",
    "`make_*` permite generar datasets sintéticos de manera programática. Sirve para experimentar con algoritmos de machine learning, probar comportamientos del modelo ante ciertos tipos de datos o validar técnicas sin necesidad de datos reales.\n",
    "\n",
    "Por ejemplo, `make_regression`, `make_classification` y otras generan datos con características controladas según parámetros definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.make_*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset sintético de regresión y gráfico de dispersión\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = datasets.make_regression(n_features=1, n_samples=100, noise=1)\n",
    "\n",
    "# X matriz. Por ejemplo: Años de experiencia\n",
    "# y vector. Por ejemplo: Salario\n",
    "\n",
    "plt.scatter(X, y);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
