{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:40.550770Z",
     "iopub.status.busy": "2021-11-30T13:00:40.550503Z",
     "iopub.status.idle": "2021-11-30T13:00:47.710183Z",
     "shell.execute_reply": "2021-11-30T13:00:47.709084Z",
     "shell.execute_reply.started": "2021-11-30T13:00:40.550742Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:47.712895Z",
     "iopub.status.busy": "2021-11-30T13:00:47.712630Z",
     "iopub.status.idle": "2021-11-30T13:00:47.719376Z",
     "shell.execute_reply": "2021-11-30T13:00:47.718592Z",
     "shell.execute_reply.started": "2021-11-30T13:00:47.712864Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:47.722148Z",
     "iopub.status.busy": "2021-11-30T13:00:47.720900Z",
     "iopub.status.idle": "2021-11-30T13:00:47.954481Z",
     "shell.execute_reply": "2021-11-30T13:00:47.953630Z",
     "shell.execute_reply.started": "2021-11-30T13:00:47.722104Z"
    }
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"/kaggle/input/pyspark-ml-nlp/SMSSpamCollection\",\n",
    "                      inferSchema = True, sep = \"\\t\")\n",
    "\n",
    "data.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:47.955886Z",
     "iopub.status.busy": "2021-11-30T13:00:47.955614Z",
     "iopub.status.idle": "2021-11-30T13:00:48.022975Z",
     "shell.execute_reply": "2021-11-30T13:00:48.022188Z",
     "shell.execute_reply.started": "2021-11-30T13:00:47.955851Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed(existing = \"_c0\", new = \"class\")\\\n",
    "           .withColumnRenamed(existing = \"_c1\", new = \"text\")\n",
    "\n",
    "data.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.028310Z",
     "iopub.status.busy": "2021-11-30T13:00:48.027292Z",
     "iopub.status.idle": "2021-11-30T13:00:48.119809Z",
     "shell.execute_reply": "2021-11-30T13:00:48.118950Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.028257Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "data = data.withColumn(colName = \"length\", col = length(data[\"text\"]))\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.121234Z",
     "iopub.status.busy": "2021-11-30T13:00:48.120932Z",
     "iopub.status.idle": "2021-11-30T13:00:48.306318Z",
     "shell.execute_reply": "2021-11-30T13:00:48.305336Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.121197Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby(\"class\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.307776Z",
     "iopub.status.busy": "2021-11-30T13:00:48.307489Z",
     "iopub.status.idle": "2021-11-30T13:00:48.319733Z",
     "shell.execute_reply": "2021-11-30T13:00:48.318813Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.307740Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.322568Z",
     "iopub.status.busy": "2021-11-30T13:00:48.321822Z",
     "iopub.status.idle": "2021-11-30T13:00:48.407045Z",
     "shell.execute_reply": "2021-11-30T13:00:48.406121Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.322519Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"text\",\n",
    "                      outputCol = \"token_text\")\n",
    "\n",
    "remover = StopWordsRemover(inputCol = \"token_text\",\n",
    "                           outputCol = \"stop_tokens\")\n",
    "\n",
    "cv = CountVectorizer(inputCol = \"stop_tokens\",\n",
    "                            outputCol = \"count_vec\")\n",
    "\n",
    "idf = IDF(inputCol = \"count_vec\",\n",
    "          outputCol = \"tf_idf\")\n",
    "\n",
    "class_indexer = StringIndexer(inputCol = \"class\",\n",
    "                              outputCol = \"label\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"tf_idf\", \"length\"],\n",
    "                            outputCol = \"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol = \"features\",\n",
    "                        outputCol = \"scaled_features\",\n",
    "                        withStd = True,\n",
    "                        withMean = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.408721Z",
     "iopub.status.busy": "2021-11-30T13:00:48.408484Z",
     "iopub.status.idle": "2021-11-30T13:00:48.415737Z",
     "shell.execute_reply": "2021-11-30T13:00:48.415122Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.408693Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(featuresCol = \"scaled_features\",\n",
    "                labelCol = \"label\",\n",
    "                predictionCol = \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:48.417267Z",
     "iopub.status.busy": "2021-11-30T13:00:48.416879Z",
     "iopub.status.idle": "2021-11-30T13:00:50.663998Z",
     "shell.execute_reply": "2021-11-30T13:00:50.663157Z",
     "shell.execute_reply.started": "2021-11-30T13:00:48.417236Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "data_pipeline = Pipeline(stages = [class_indexer, tokenizer, remover, cv, idf, assembler, scaler])\n",
    "\n",
    "df = data_pipeline.fit(data).transform(data)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:50.665403Z",
     "iopub.status.busy": "2021-11-30T13:00:50.665138Z",
     "iopub.status.idle": "2021-11-30T13:00:50.868016Z",
     "shell.execute_reply": "2021-11-30T13:00:50.867101Z",
     "shell.execute_reply.started": "2021-11-30T13:00:50.665369Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.select(\"label\", \"scaled_features\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:50.874873Z",
     "iopub.status.busy": "2021-11-30T13:00:50.869227Z",
     "iopub.status.idle": "2021-11-30T13:00:50.889298Z",
     "shell.execute_reply": "2021-11-30T13:00:50.888441Z",
     "shell.execute_reply.started": "2021-11-30T13:00:50.874824Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit(weights = [0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:50.894130Z",
     "iopub.status.busy": "2021-11-30T13:00:50.893822Z",
     "iopub.status.idle": "2021-11-30T13:00:52.425344Z",
     "shell.execute_reply": "2021-11-30T13:00:52.424448Z",
     "shell.execute_reply.started": "2021-11-30T13:00:50.894093Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nb.fit(train)\n",
    "\n",
    "y_hat = model.transform(test)\n",
    "\n",
    "y_hat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:00:52.428433Z",
     "iopub.status.busy": "2021-11-30T13:00:52.428134Z",
     "iopub.status.idle": "2021-11-30T13:00:53.055123Z",
     "shell.execute_reply": "2021-11-30T13:00:53.054174Z",
     "shell.execute_reply.started": "2021-11-30T13:00:52.428393Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\",\n",
    "                                              metricName = \"accuracy\")\n",
    "accuracy = evaluator.evaluate(y_hat)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
