{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Documentacion:** http://spark.apache.org/docs/latest/ml-features.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LinearRegression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path = \"/kaggle/input/pyspark-ml/fake_customers.csv\", \n",
    "                    inferSchema = True, header = True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndexer\n",
    "\n",
    "Para transformar los valores categoricos a numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer1 = StringIndexer(inputCol = \"Group\",\n",
    "                         outputCol = \"GroupIndex\")\n",
    "\n",
    "indexed1 = indexer1.fit(df).transform(df)\n",
    "\n",
    "indexed1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer2 = StringIndexer(inputCol = \"Name\",\n",
    "                         outputCol = \"NameIndex\")\n",
    "\n",
    "indexed2 = indexer2.fit(indexed1).transform(indexed1)\n",
    "\n",
    "indexed2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T20:16:34.660394Z",
     "iopub.status.busy": "2021-11-28T20:16:34.660043Z",
     "iopub.status.idle": "2021-11-28T20:16:34.665394Z",
     "shell.execute_reply": "2021-11-28T20:16:34.664291Z",
     "shell.execute_reply.started": "2021-11-28T20:16:34.660358Z"
    }
   },
   "source": [
    "### VectorIndexer\n",
    "Para transformar los datos a un vector denso. Esto es obligatorio para los modelos de ML en PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"Phone\", \"GroupIndex\", \"NameIndex\"],\n",
    "                            outputCol = \"features\")\n",
    "\n",
    "output = assembler.transform(indexed2)\n",
    "\n",
    "output.select([\"Phone\", \"GroupIndex\", \"NameIndex\", \"features\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"/kaggle/input/pyspark-ml/sample_linear_regression_data.txt\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el formato que Spark usa para hacer ML, dos columnas, una llamada \"label\" y otra de \"features\", que serían \"y\" y \"X\" respectivamente.\n",
    "\n",
    "La columna \"label\" o \"y\" debe ser una columna numerica, al igual que cuando haciamos modelos de SciKit-Learn.\n",
    "\n",
    "La columna \"features\" o \"X\" esta formada por vectores , estos vectores son los elementos agrupados de las columnas iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo\n",
    "lr = LinearRegression(featuresCol = \"features\",\n",
    "                      labelCol = \"label\",\n",
    "                      predictionCol = \"prediction\")\n",
    "\n",
    "# Nota: si en el DataFrame las columnas tienen otros nombres podemos decirle al modelo que trabaje con esos nombres\n",
    "# Por convencion \"X\" se llama \"features\", \"y\" se llama \"label\" y las predicciones se llaman \"prediction\"\n",
    "# Y esos son los valores por defecto de los modelo de ML.\n",
    "\n",
    "# Entrenamos el modelo \n",
    "model = lr.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos imprimir los coeficientes de la regresion\n",
    "print(\"Coeficientes: {}\".format(str(model.coefficients)))\n",
    "print(\"\\n\")\n",
    "print(\"Intercepcion:{}\".format(str(model.intercept)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modelo tiene el metodo .summary\n",
    "# Este summary se hace sobre el set de entrenamiento y calcula las metricas del modelo\n",
    "summary = model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.residuals.show()\n",
    "# .residuals es la diferencia entre el valor real y el valor predicho \n",
    "\n",
    "print(\"RMSE: {}\".format(summary.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(summary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "No existe la función **train_test_split**... Pero los objetos DataFrames de Spark tienen un método que hace lo mismo que **train_test_split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .randomSplit()\n",
    "\n",
    "train, test = data.randomSplit(weights = [0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show(3)\n",
    "\n",
    "test.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.residuals.show()\n",
    "print(\"RMSE: {}\".format(y_hat.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí llegaría el modelo, ahora vamos a ver como hacer predicciones de datos nuevos.\n",
    "\n",
    "Vamos a trabajar con la columna de \"features\" de test, así solo nos quedamos con \"X\" y no sabemos el valor de \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_data = test.select(\"features\")\n",
    "nueva_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En lugar de usar .evaluate() vamos a usar .transform() y esto nos retorna un nuevo DataFrame\n",
    "y_hat = model.transform(nueva_data)\n",
    "y_hat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path = \"modelo.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
